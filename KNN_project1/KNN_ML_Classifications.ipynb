{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ea6420-b0de-47cf-933f-0e3d6a4192b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series\n",
    "pd.set_option('display.max_columns', None) # set pd.options.display features\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy as np # for multi array manipÃ¼lation process,Linear algebra\n",
    "import seaborn as sns # for data visulations,its very usefully\n",
    "import matplotlib.pyplot as plt # for data visulations\n",
    "plt.rcParams[\"figure.figsize\"]=(18,8)\n",
    "from matplotlib.colors import ListedColormap # for color palette for plots\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "from sklearn import utils\n",
    "from sklearn.preprocessing import StandardScaler #for normalization and data scaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # fro trainins,test ,validaitons ana model hyperparameters tuning\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score,classification_report # for models evaulations \n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor # for model build, outlier detections\n",
    "from sklearn.decomposition import PCA # for dimentional reductions .Principle compomnet Analys\n",
    "from sklearn.datasets import load_breast_cancer # for datasets \n",
    "# closed warning library\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# include data \n",
    "try:\n",
    "    \n",
    "    data = pd.read_csv(\"breast_cancer.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    \n",
    "    print(type(e))\n",
    "    print(e)\n",
    "    #from import datasets from sklearn if CSV FİLE İS NOT FOUND\n",
    "    data=load_breast_cancer()\n",
    "\n",
    "#create df  if CSV FİLE İS NOT FOUND\n",
    "if type(data)==utils.Bunch:\n",
    "    df=np.concatenate((data.target.reshape(-1,1),data.data), axis=1)\n",
    "    data=pd.DataFrame(df,columns=np.insert(data.feature_names,0,\"diagnosis\"))\n",
    "else:\n",
    "    # remove unnecesssary columns\n",
    "    data.drop(['Unnamed: 32','id'], inplace = True, axis = 1)\n",
    "\n",
    "data = data.rename(columns = {\"diagnosis\":\"Dependent\"})\n",
    "data_=data.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f92457a-803a-40e5-8daf-83fe28fe811c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='count', ylabel='Dependent'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y=data_[\"Dependent\"],\n",
    "                   linewidth=5,\n",
    "                   edgecolor=sns.color_palette(\"dark\", 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e61240-8c8b-4ea2-a081-a868c35e8ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    357\n",
      "0.0    212\n",
      "Name: Dependent, dtype: int64\n",
      "569\n",
      "   Dependent  mean radius  mean texture  mean perimeter  mean area  \\\n",
      "0        0.0        17.99         10.38          122.80     1001.0   \n",
      "1        0.0        20.57         17.77          132.90     1326.0   \n",
      "2        0.0        19.69         21.25          130.00     1203.0   \n",
      "3        0.0        11.42         20.38           77.58      386.1   \n",
      "4        0.0        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   mean symmetry  mean fractal dimension  radius error  texture error  \\\n",
      "0         0.2419                 0.07871        1.0950         0.9053   \n",
      "1         0.1812                 0.05667        0.5435         0.7339   \n",
      "2         0.2069                 0.05999        0.7456         0.7869   \n",
      "3         0.2597                 0.09744        0.4956         1.1560   \n",
      "4         0.1809                 0.05883        0.7572         0.7813   \n",
      "\n",
      "   perimeter error  area error  smoothness error  compactness error  \\\n",
      "0            8.589      153.40          0.006399            0.04904   \n",
      "1            3.398       74.08          0.005225            0.01308   \n",
      "2            4.585       94.03          0.006150            0.04006   \n",
      "3            3.445       27.23          0.009110            0.07458   \n",
      "4            5.438       94.44          0.011490            0.02461   \n",
      "\n",
      "   concavity error  concave points error  symmetry error  \\\n",
      "0          0.05373               0.01587         0.03003   \n",
      "1          0.01860               0.01340         0.01389   \n",
      "2          0.03832               0.02058         0.02250   \n",
      "3          0.05661               0.01867         0.05963   \n",
      "4          0.05688               0.01885         0.01756   \n",
      "\n",
      "   fractal dimension error  worst radius  worst texture  worst perimeter  \\\n",
      "0                 0.006193         25.38          17.33           184.60   \n",
      "1                 0.003532         24.99          23.41           158.80   \n",
      "2                 0.004571         23.57          25.53           152.50   \n",
      "3                 0.009208         14.91          26.50            98.87   \n",
      "4                 0.005115         22.54          16.67           152.20   \n",
      "\n",
      "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   worst concave points  worst symmetry  worst fractal dimension  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "Data shape  (569, 31)\n"
     ]
    }
   ],
   "source": [
    "print(data.Dependent.value_counts())\n",
    "\n",
    "if not data.Dependent.dtype in [np.float64,np.int64]:\n",
    "    \n",
    "    data[\"Dependent\"] = [0 if i.strip() == \"M\" else 1 for i in data.Dependent]\n",
    "\n",
    "elif  data.Dependent.dtype in [np.float64,np.int64]:\n",
    "    data_[\"Dependent\"] = [\"Malignant\" if i==0 else  \"Belign\"  for i in data.Dependent]\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "print(\"Data shape \", data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988187da-5428-447d-a6b0-9c3ef6273239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae956f9e-f033-4fe4-a3e7-f0e7701d9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#%% tools for EDA for Datasets\n",
    "\n",
    "from dataprep.eda import create_report\n",
    "create_report(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6dd284-6e31-4548-bdad-4fe8e53fe543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% exploratory data analysis\n",
    "y_depent=\"Dependent\"\n",
    "x_indepent=columns_features[1:]\n",
    "# fully Feature Correlation\n",
    "corr_matrix = data.corr()\n",
    "#print(corr_matrix)\n",
    "\n",
    "#dependent variable correlations with independent other features\n",
    "sns.heatmap(corr_matrix[[y_depent]].sort_values(by=y_depent), annot = True, fmt = \".2f\",xticklabels=True, yticklabels=True)\n",
    "plt.title(\"Correlation Between Features\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# for dependent subsample correlations\n",
    "thresh = 0.70\n",
    "filtre = np.abs(corr_matrix[y_depent]) < thresh\n",
    "corr_features=np.append(corr_matrix.columns[filtre].to_numpy(),[y_depent])\n",
    "sns.clustermap(data[corr_features].corr(), annot = True, fmt = \".2f\")\n",
    "plt.title(f\"Correlation Between Features threshold= {thresh}\")\n",
    "plt.show()\n",
    "#there some correlated features.We drop out these features because of we improve models\n",
    "\n",
    "filtres_corr=[ corr_matrix[corr_features].corr()[i]<0.70 for i in corr_features]\n",
    "\n",
    "for i,ser in enumerate(filtres_corr):\n",
    "    ser.reset_index(drop=True,inplace=True)\n",
    "    corr_matrix[corr_features].corr()[]\n",
    "\n",
    "corr_matrix_filer=[corr_matrix<.75]\n",
    "\n",
    "corr_pairs=corr_matrix.unstack()\n",
    "\n",
    "sorted_pairs = corr_pairs.sort_values(kind=\"quicksort\")\n",
    "\n",
    "strong_pairs = sorted_pairs[(abs(sorted_pairs) <0.70)]\n",
    "\n",
    "threscorr_pairs=strong_pairs.sort_index(level=0).unstack(level=1)\n",
    "\n",
    "\n",
    "\n",
    "sns.heatmap(threscorr_pairs, annot = True, fmt = \".2f\",xticklabels=True, yticklabels=True)\n",
    "plt.title(\"Correlation Between Features\")\n",
    "plt.show()\n",
    "#Correlations\n",
    "\n",
    "?pd.reset_index()\n",
    "x_vars = corr_features[:5]\n",
    "y_vars = corr_features[:5]\n",
    "g = sns.PairGrid(data_, hue=\"Dependent\",x_vars=x_vars, y_vars=y_vars)\n",
    "g.map_diag(sns.kdeplot, color=\".3\")\n",
    "g.map_offdiag(sns.scatterplot)\n",
    "g.add_legend()\n",
    "\n",
    "\n",
    "# pair plot \n",
    "sns.pairplot(data_[corr_features[6:]], diag_kind = \"kde\", markers = \"+\",hue = \"Dependent\")\n",
    "# Kind of plot to make.\n",
    "# kind{'scatter', 'kde', 'hist', 'reg'}\n",
    "#Kind of plot for the diagonal subplots\n",
    "# diag_kind{'auto', 'hist', 'kde', None}\n",
    "plt.show()\n",
    "\"\"\"\n",
    "if we see kde plot .our data has positive skewness.we have to make outlier detecions to get rid of this outlier datas\n",
    "\"\"\"\n",
    "\n",
    "# %% outlier Detections \n",
    "\n",
    "def outliers(df,variables):\n",
    "        if isinstance(variables,(np.ndarray,list)):\n",
    "            variables=variables\n",
    "        else:\n",
    "            variables=np.expand_dims(variables,axis=0)\n",
    "             \n",
    "        QR_dicts={}\n",
    "        for v in variables:\n",
    "            q1=df[v].quantile(0.25)\n",
    "            q2=df[v].quantile(0.5)\n",
    "            q3=df[v].quantile(0.75)\n",
    "            IQRange=q3-q2 \n",
    "            low_bound=q1-(IQRange*1.5)\n",
    "            high_bound=q3+(IQRange*1.5)\n",
    "                   \n",
    "            lower_filter=df[v]<low_bound\n",
    "            upper_filter=df[v]>high_bound\n",
    "            \n",
    "        \n",
    "            lower_outlier=df.loc[lower_filter,v]\n",
    "            upper_outlier=df.loc[upper_filter,v]\n",
    "            QR_dicts[v]={\"low_bound\":low_bound,\n",
    "                         \"q1\":q1,\n",
    "                         \"q2\":q2,\n",
    "                         \"q3\":q3,\n",
    "                         \"high_bound\":high_bound,\n",
    "                         \"lower_outlier\":lower_outlier,\n",
    "                         \"upper_outlier\":upper_outlier,\n",
    "                         \"mean\":df[v].mean(),\n",
    "                         \"IORange\":IQRange,\n",
    "                         \"std\":df[v].std(),\n",
    "                         \"pearson Skewness Coef\":(3*(df[v].mean()-df[v].median())/df[v].std())}\n",
    "            \n",
    "       \n",
    "        return QR_dicts\n",
    "    \n",
    "\n",
    "    \n",
    "#%% boxplot \n",
    "def show_boxplot(df,id_var,column_vars,hue=\"Dependent\",orien=\"h\",box=True,swarm=False,Quantil=None):\n",
    "        \n",
    "        plt.style.use('fivethirtyeight')\n",
    "         # box plot \n",
    "        data_melted = pd.melt(df,\n",
    "                              id_vars = id_var,\n",
    "                              value_vars=column_vars,\n",
    "                              var_name =\"columns_features\",\n",
    "                              value_name =\"Feature_values\")\n",
    "        \n",
    "        # data_pivot= data_melted.pivot_table(\n",
    "        #                               columns=data_melted.columns[1],\n",
    "        #                               values=data_melted.columns[2])\n",
    "           # Colors\n",
    "        BG_WHITE = \"#fbf9f4\"\n",
    "        RED_DARK = \"#850e00\"\n",
    "        fig, ax = plt.subplots(figsize= (14, 10))\n",
    "    \n",
    "        \n",
    "        # Some layout stuff ----------------------------------------------\n",
    "        # Background color\n",
    "        fig.patch.set_facecolor(BG_WHITE)\n",
    "        ax.set_facecolor(BG_WHITE)\n",
    "        \n",
    "        if orien==\"h\":\n",
    "            if box==True:\n",
    "                ax=sns.boxplot(y = \"columns_features\", x = \"Feature_values\", hue = hue, data = data_melted,\n",
    "                          whis=1.5, width=.8, palette=\"husl\")\n",
    "                # ax=sns.violinplot(y = \"columns_features\", x = \"Feature_values\", hue = hue, data = data_melted,alpha=.2,\n",
    "                #               palette=\"flare\",scale=\"area\", width=5)\n",
    "            if swarm==True:\n",
    "            # Add in points to show each observation\n",
    "                ax=sns.swarmplot( y = \"columns_features\", x = \"Feature_values\", data=data_melted,\n",
    "                      size=3, color=\".2\", linewidth=1)\n",
    "            plt.xticks(rotation = 0)\n",
    "        \n",
    "        else:\n",
    "            if box==True:\n",
    "                ax=sns.boxplot(x = \"columns_features\", y = \"Feature_values\", hue = hue, data = data_melted,\n",
    "                             whis=1.5, width=.8, palette=\"husl\")\n",
    "                # ax=sns.violinplot(x = \"columns_features\", y = \"Feature_values\", hue = hue, data = data_melted,alpha=.2,\n",
    "                #               palette=\"flare\",\n",
    "                #         scale=\"area\", width=5 )\n",
    "            if swarm==True:\n",
    "                ax=sns.swarmplot( x = \"columns_features\", y = \"Feature_values\", data=data_melted,\n",
    "                                    size=3, color=\".2\", linewidth=1)\n",
    "            plt.xticks(rotation = 90)\n",
    "        if Quantil!=None and len(Quantil)>1 :\n",
    "            \n",
    "            for i, (k,info_dict) in enumerate(QR_dicts.items()):\n",
    "            \n",
    "                for key,value in info_dict.items():\n",
    "                        if not key in [\"IORange\",\"lower_outlier\",\"pearson Skewness Coef\",\"std\",\"upper_outlier\"]:\n",
    "                            if orien==\"v\":\n",
    "                                ax.scatter([i], [value], color=\"red\",s=10, zorder=10)\n",
    "                                # Add mean value label.\n",
    "                                if key ==\"mean\":\n",
    "                                    ax.text(\n",
    "                                            i,\n",
    "                                            value,\n",
    "                                            r\"$\\hat{\\mu}_{\\rm{mean}} = $\" + str(round(value, 3)),\n",
    "                                            fontsize=10,\n",
    "                                            va=\"center\",\n",
    "                                            bbox = dict(\n",
    "                                                facecolor=\"white\",\n",
    "                                                edgecolor=\"black\",\n",
    "                                                boxstyle=\"round\",\n",
    "                                                pad=0.0\n",
    "                                            ),zorder=20 # to make sure the line is on top\n",
    "                                            )\n",
    "                            else:\n",
    "                                ax.scatter([value],[i],ls=\"dashdot\", color=\"red\",s=10, zorder=10)\n",
    "                            # Add mean value label.\n",
    "                                if key ==\"mean\":\n",
    "                                    ax.text(\n",
    "                                                value,\n",
    "                                                i,\n",
    "                                                r\"$\\hat{\\mu}_{\\rm{mean}} = $\" + str(round(value, 3)),\n",
    "                                                fontsize=10,\n",
    "                                                va=\"center\",\n",
    "                                                rotation=90,\n",
    "                                                bbox = dict(\n",
    "                                                    facecolor=\"white\",\n",
    "                                                    edgecolor=\"black\",\n",
    "                                                    boxstyle=\"round\",\n",
    "                                                    ),zorder=20 # to make sure the line is on top\n",
    "                                                )\n",
    "                \n",
    "        plt.title('Boxplots for Selected Features', fontdict={'fontweight':'bold', 'fontsize': 18})\n",
    "      \n",
    "            \n",
    "        #ax.set_yticks([0, .5, 1])\n",
    "        #ax.set_xticks(np.arange(0, 270,10))\n",
    "        #ax.set_xlim(0, 5)\n",
    "        ax.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        return True,data_melted\n",
    "    \n",
    " #if we see boxplot, we should be stardardization,normalizations.\n",
    " #also we have outlier data point\n",
    " #our data has diferent range  .we have to make standardization-normalization to bring everyone in the same range datas\n",
    " #%% analyzing outliers\n",
    "#fancyindex=[3,13,22,23] # big scale features\n",
    "fancyindex=[np.arange(1,31,1)]\n",
    "QR_dicts=outliers(data,columns_features[fancyindex])\n",
    "_,Data_melted=show_boxplot(data,\"Dependent\",columns_features[fancyindex],None,\"h\",True,False,None)\n",
    "\n",
    "sns.jointplot(y = \"Feature_values\", x = \"Feature_values\", hue = \"columns_features\", data = Data_melted ,kind=\"scatter\")\n",
    "     \n",
    "\n",
    "#%% Local outlier Detections for Skewness Datas\n",
    "y = data.Dependent\n",
    "x = data.drop([\"Dependent\"],axis = 1)\n",
    "x_columns = x.columns.tolist()\n",
    "#Unsupervised Outlier Detection using Local Outlier Factor (LOF)\n",
    "\n",
    "# which is the average local reachability density of the neighbors divided by the object's own local reachability density. A value of approximately 1 indicates that the object is comparable to its neighbors (and thus not an outlier). A value below 1 indicates a denser region (which would be an inlier), while values significantly larger than 1 indicate outliers.\n",
    "\n",
    "# LOF(k) ~ 1 means Similar density as neighbors,\n",
    "\n",
    "# LOF(k) < 1 means Higher density than neighbors (Inlier),\n",
    "\n",
    "# LOF(k) > 1 means Lower density than neighbors (Outlier)\n",
    "clf = LocalOutlierFactor()\n",
    "y_pred = clf.fit_predict(x)\n",
    "X_score = clf.negative_outlier_factor_\n",
    "#The opposite LOF of the training samples. \n",
    "# The higher, the more normal.\n",
    "#  Inliers tend to have a LOF score close to 1 (negative_outlier_factor_ close to -1)\n",
    "#  , while outliers tend to have a larger LOF score\n",
    "\n",
    "# in this data, Inliers tend to have a LOF score close to  -0.946074\n",
    "#outliers tend to have a LOF score close to -3.13447\n",
    "outlier_score = pd.DataFrame()\n",
    "outlier_score[\"score\"] = X_score\n",
    "\n",
    "#set outlier threshold value\n",
    "threshold = -1.6\n",
    "filtre = outlier_score[\"score\"] < threshold\n",
    "outlier_index = outlier_score[filtre].index.tolist()\n",
    "\n",
    "#we make normalizaiton.therefore we will scale the data between 0 and 1\n",
    "# if score close to 1,its outlier,if score close to 0 ,its inlier\n",
    "radius = (X_score.max() - X_score)/(X_score.max() - X_score.min())\n",
    "outlier_score[\"radius\"] = radius\n",
    "sns.scatterplot(x.loc[:,\"worst area\"], x.loc[:,\"mean area\"], color = \"g\", s = 20, label = \"Data Points\")\n",
    "# we draw a circle around the outliers\n",
    "plt.scatter(x.loc[outlier_index,\"worst area\"], x.loc[outlier_index,\"mean area\"], s = 1000*radius[outlier_index], edgecolors = \"red\",facecolors = \"none\", label = \"Outlier Scores\")\n",
    "plt.ylabel(\"mean area\")\n",
    "plt.xlabel(\"worst area\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# drop outliers value\n",
    "x = x.drop(outlier_index)\n",
    "y = y.drop(outlier_index).values\n",
    "\n",
    "# %% Train test split\n",
    "test_size = 0.3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = test_size, random_state = 42)\n",
    "\n",
    "# %% standardization-normalization-scalering\n",
    "\n",
    "# we transform data to mü =0 std=1 \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "df = pd.DataFrame(X_train, columns = columns)\n",
    "df_describe = df.describe()\n",
    "df[\"Dependent\"] = Y_train\n",
    "# box plot \n",
    "data_meltedd= pd.melt(df, id_vars = \"Dependent\",\n",
    "                      value_vars=df.columns[:-1],\n",
    "                      var_name =\"columns_features\",\n",
    "                      value_name =\"Feature_values\")\n",
    "\n",
    "sns.boxplot(x= \"columns_features\", y= \"Feature_values\", hue = \"Dependent\", data = data_meltedd)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"after standardizations for data\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# pair plot \n",
    "sns.pairplot(df[corr_features], diag_kind = \"kde\", markers = \"+\",hue = \"Dependent\")\n",
    "plt.title(\"data pairplot its correlations threshold >0,75 \")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# %% Basic KNN Method\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 2)\n",
    "knn.fit(X_train, Y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\".2f\")\n",
    "acc_score = accuracy_score(Y_test, y_pred)\n",
    "ac_score = knn.score(X_test, Y_test)\n",
    "print(\"Valid Accurancy Score: \",acc_score)\n",
    "print(\"Confusion matrix: \",cm)\n",
    "print(\"Basic KNN Acc: \",ac_score)\n",
    "print(\"Train Accurancy Score: \",knn.score(X_train,Y_train))\n",
    "\n",
    "\n",
    "# %% choose best parameters\n",
    "\n",
    "def Model_Tune_Params(model,x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    k_range = list(range(1,31))\n",
    "    weight_options = [\"uniform\",\"distance\"]\n",
    "    p=np.arange(1,8,1)\n",
    "    \n",
    "    param_grid = dict(n_neighbors = k_range, weights = weight_options,p=p)\n",
    "    \n",
    "    best_model = GridSearchCV(model, param_grid, cv = 10, scoring = \"roc_auc\")\n",
    "    best_model.fit(x_train, y_train)\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "knn = KNeighborsClassifier()    \n",
    "grid = Model_Tune_Params(knn,X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "print(\"Best training score: {} with parameters: {}\".format(grid.best_score_, grid.best_params_))\n",
    "#%% build  Model \n",
    "\n",
    "knn = KNeighborsClassifier(**grid.best_params_)\n",
    "knn.fit(X_train, Y_train)\n",
    "y_pred_train = knn.predict(X_train)\n",
    "y_pred_test = knn.predict(X_test)\n",
    "\n",
    "\n",
    "cm_test = confusion_matrix(Y_test, y_pred_test)\n",
    "cm_train = confusion_matrix(Y_train, y_pred_train)\n",
    "\n",
    "# plot for confusion matrix tran and Valid Data Sets\n",
    "fig ,axes=plt.subplots(nrows=1, ncols=2)\n",
    "fig.suptitle('confusion matrix Tran & Valid')\n",
    "sns.heatmap(ax=axes[0],data=cm_train,annot=True,fmt=\".2f\")\n",
    "axes[0].set_title(\"Train Data Confusion matrix\")\n",
    "sns.heatmap(ax=axes[1],data=cm_test,annot=True,fmt=\".2f\")\n",
    "axes[1].set_title(\"Valid Data Confusion matrix\")\n",
    "\n",
    "\n",
    "acc_test = accuracy_score(Y_test, y_pred_test)\n",
    "acc_train = accuracy_score(Y_train, y_pred_train)\n",
    "print(\"Test Score: {}, Train Score: {}\".format(acc_test, acc_train))\n",
    "print(\"Cassificaitons report: \\n \",classification_report(Y_test,y_pred_test))\n",
    "print(\"CM Train: \", cm_train)\n",
    "\n",
    "#%% Saving Model\n",
    "\n",
    "# open a file, where you ant to store the data\n",
    "file = open('KNN_project1/KNN_model.pkl', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(Breast_KNN_moddel, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
